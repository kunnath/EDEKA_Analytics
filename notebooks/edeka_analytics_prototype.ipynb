{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee819b2c",
   "metadata": {},
   "source": [
    "# EDEKA Analytics Application Prototype\n",
    "\n",
    "This notebook demonstrates a prototype for analyzing product performance and customer behavior for EDEKA supermarket chain. It includes:\n",
    "\n",
    "1. Product Sales Analysis - Track which products sell fastest and analyze sales by category\n",
    "2. Customer Purchase Behavior - Identify repeat customers and analyze purchase patterns\n",
    "3. Data Privacy Considerations - Demonstrate data anonymization for GDPR compliance\n",
    "4. Visualization Techniques - Create charts for the dashboard\n",
    "\n",
    "The analysis in this notebook will serve as the foundation for a full analytics application with a React frontend and Python/Flask backend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8766556",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import Python libraries for data analysis, visualization, and API prototyping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201639da",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhashlib\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Import visualization libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpx\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Import data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Import Flask for API prototyping\n",
    "from flask import Flask, jsonify\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4602b0",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Sample Data\n",
    "\n",
    "For this prototype, we'll generate sample data that follows the structure outlined in the requirements:\n",
    "\n",
    "- **Categories**: Product categories like fruits, dairy, meat, etc.\n",
    "- **Products**: Individual products with ID, name, category, and quality\n",
    "- **Customers**: Customer profiles with card ID, name, nationality, and age\n",
    "- **Bills**: Transaction records with bill ID, card ID, and timestamp\n",
    "- **BillItems**: Individual items in each bill with product ID, quantity, and price\n",
    "\n",
    "Let's generate and explore this sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dbdb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample Categories data\n",
    "categories_data = {\n",
    "    'category_id': list(range(1, 11)),\n",
    "    'name': [\n",
    "        'Fruits & Vegetables',\n",
    "        'Dairy',\n",
    "        'Meat',\n",
    "        'Bakery',\n",
    "        'Frozen Foods',\n",
    "        'Beverages',\n",
    "        'Snacks',\n",
    "        'Household',\n",
    "        'Health & Beauty',\n",
    "        'Deli'\n",
    "    ]\n",
    "}\n",
    "\n",
    "categories_df = pd.DataFrame(categories_data)\n",
    "print(\"Categories Dataset:\")\n",
    "display(categories_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample Products data with quality rating (1-5)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Sample products by category\n",
    "product_names = {\n",
    "    1: ['Apples', 'Bananas', 'Carrots', 'Tomatoes', 'Spinach', 'Potatoes', 'Onions', 'Broccoli', 'Strawberries', 'Grapes'],\n",
    "    2: ['Milk', 'Cheese', 'Yogurt', 'Butter', 'Cream', 'Sour Cream', 'Cottage Cheese', 'Cream Cheese', 'Ice Cream', 'Whipped Cream'],\n",
    "    3: ['Chicken', 'Beef', 'Pork', 'Turkey', 'Lamb', 'Ground Beef', 'Sausages', 'Bacon', 'Ham', 'Steak'],\n",
    "    4: ['Bread', 'Rolls', 'Baguette', 'Croissants', 'Donuts', 'Muffins', 'Cake', 'Cookies', 'Pie', 'Pastries'],\n",
    "    5: ['Frozen Pizza', 'Ice Cream', 'Frozen Vegetables', 'Frozen Meals', 'Frozen Fruit', 'Frozen Fish', 'Frozen Desserts', 'Frozen Breakfast', 'Frozen Snacks', 'Frozen Meat'],\n",
    "    6: ['Water', 'Soda', 'Juice', 'Coffee', 'Tea', 'Beer', 'Wine', 'Energy Drinks', 'Sports Drinks', 'Milk Alternatives'],\n",
    "    7: ['Chips', 'Crackers', 'Pretzels', 'Popcorn', 'Nuts', 'Chocolate', 'Candy', 'Granola Bars', 'Trail Mix', 'Cookies'],\n",
    "    8: ['Cleaning Supplies', 'Paper Towels', 'Toilet Paper', 'Laundry Detergent', 'Dish Soap', 'Trash Bags', 'Air Freshener', 'Sponges', 'Bleach', 'All-Purpose Cleaner'],\n",
    "    9: ['Shampoo', 'Conditioner', 'Soap', 'Toothpaste', 'Deodorant', 'Lotion', 'Sunscreen', 'Razors', 'Makeup', 'Vitamins'],\n",
    "    10: ['Sliced Meat', 'Sliced Cheese', 'Salads', 'Olives', 'Hummus', 'Prepared Meals', 'Sandwiches', 'Sushi', 'Rotisserie Chicken', 'Soup']\n",
    "}\n",
    "\n",
    "# Generate product data\n",
    "products_data = {\n",
    "    'product_id': [],\n",
    "    'name': [],\n",
    "    'category_id': [],\n",
    "    'quality': [],  # Quality rating 1-5 (5 being highest)\n",
    "    'price': [],\n",
    "    'stock_date': []  # When the product was stocked\n",
    "}\n",
    "\n",
    "product_id = 1\n",
    "for category_id, names in product_names.items():\n",
    "    for name in names:\n",
    "        products_data['product_id'].append(product_id)\n",
    "        products_data['name'].append(name)\n",
    "        products_data['category_id'].append(category_id)\n",
    "        products_data['quality'].append(np.random.randint(1, 6))  # Random quality 1-5\n",
    "        products_data['price'].append(round(np.random.uniform(0.99, 29.99), 2))  # Random price\n",
    "        \n",
    "        # Random stock date within the last 30 days\n",
    "        stock_date = datetime.now() - timedelta(days=np.random.randint(1, 31))\n",
    "        products_data['stock_date'].append(stock_date)\n",
    "        \n",
    "        product_id += 1\n",
    "\n",
    "products_df = pd.DataFrame(products_data)\n",
    "print(\"Products Dataset (first 10 rows):\")\n",
    "display(products_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c754b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample Customers data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Sample first names, last names, and nationalities\n",
    "first_names = ['Emma', 'Noah', 'Olivia', 'Liam', 'Sophia', 'Mason', 'Ava', 'Jacob', 'Isabella', 'William',\n",
    "               'Mia', 'Ethan', 'Charlotte', 'James', 'Amelia', 'Alexander', 'Abigail', 'Michael', 'Emily', 'Benjamin',\n",
    "               'Lukas', 'Hannah', 'Matthias', 'Anna', 'Felix', 'Sarah', 'Maximilian', 'Laura', 'Jonas', 'Julia']\n",
    "\n",
    "last_names = ['Schmidt', 'MÃ¼ller', 'Schneider', 'Fischer', 'Weber', 'Meyer', 'Wagner', 'Becker', 'Schulz', 'Hoffmann',\n",
    "              'Smith', 'Johnson', 'Williams', 'Jones', 'Brown', 'Davis', 'Miller', 'Wilson', 'Moore', 'Taylor',\n",
    "              'Anderson', 'Thomas', 'Jackson', 'White', 'Harris', 'Martin', 'Thompson', 'Garcia', 'Martinez', 'Robinson']\n",
    "\n",
    "nationalities = ['German', 'French', 'Italian', 'Spanish', 'Polish', 'Dutch', 'British', 'Turkish', 'Russian', 'Austrian']\n",
    "\n",
    "# Generate customer data\n",
    "num_customers = 100\n",
    "customers_data = {\n",
    "    'card_id': list(range(1001, 1001 + num_customers)),\n",
    "    'first_name': np.random.choice(first_names, num_customers),\n",
    "    'last_name': np.random.choice(last_names, num_customers),\n",
    "    'nationality': np.random.choice(nationalities, num_customers),\n",
    "    'age': np.random.randint(18, 80, num_customers),\n",
    "    'registration_date': [datetime.now() - timedelta(days=np.random.randint(1, 365*3)) for _ in range(num_customers)]  # Random registration within last 3 years\n",
    "}\n",
    "\n",
    "customers_df = pd.DataFrame(customers_data)\n",
    "print(\"Customers Dataset (first 10 rows):\")\n",
    "display(customers_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample Bills and BillItems data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Generate transaction data over the last 30 days\n",
    "num_bills = 500\n",
    "bill_start_id = 10001\n",
    "\n",
    "bills_data = {\n",
    "    'bill_id': list(range(bill_start_id, bill_start_id + num_bills)),\n",
    "    'card_id': np.random.choice(customers_df['card_id'], num_bills),\n",
    "    'timestamp': [datetime.now() - timedelta(days=np.random.randint(1, 31), \n",
    "                                           hours=np.random.randint(8, 21), \n",
    "                                           minutes=np.random.randint(0, 60)) \n",
    "                for _ in range(num_bills)],\n",
    "    'store_id': np.random.randint(1, 11, num_bills)  # 10 different stores\n",
    "}\n",
    "\n",
    "bills_df = pd.DataFrame(bills_data)\n",
    "bills_df = bills_df.sort_values('timestamp')\n",
    "\n",
    "# Generate bill items data\n",
    "bill_items_data = {\n",
    "    'bill_item_id': [],\n",
    "    'bill_id': [],\n",
    "    'product_id': [],\n",
    "    'quantity': [],\n",
    "    'unit_price': [],\n",
    "    'total_price': []\n",
    "}\n",
    "\n",
    "bill_item_id = 1\n",
    "for bill_id in bills_df['bill_id']:\n",
    "    # Each bill has 1-15 items\n",
    "    num_items = np.random.randint(1, 16)\n",
    "    # Select random products\n",
    "    products = products_df.sample(num_items)\n",
    "    \n",
    "    for _, product in products.iterrows():\n",
    "        quantity = np.random.randint(1, 6)  # 1-5 quantity per product\n",
    "        unit_price = product['price']\n",
    "        total_price = round(quantity * unit_price, 2)\n",
    "        \n",
    "        bill_items_data['bill_item_id'].append(bill_item_id)\n",
    "        bill_items_data['bill_id'].append(bill_id)\n",
    "        bill_items_data['product_id'].append(product['product_id'])\n",
    "        bill_items_data['quantity'].append(quantity)\n",
    "        bill_items_data['unit_price'].append(unit_price)\n",
    "        bill_items_data['total_price'].append(total_price)\n",
    "        \n",
    "        bill_item_id += 1\n",
    "\n",
    "bill_items_df = pd.DataFrame(bill_items_data)\n",
    "\n",
    "print(\"Bills Dataset (first 10 rows):\")\n",
    "display(bills_df.head(10))\n",
    "\n",
    "print(\"\\nBill Items Dataset (first 10 rows):\")\n",
    "display(bill_items_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sold dates based on bills data to analyze sales velocity\n",
    "# We'll create a dataframe that tracks when products were stocked and when they sold out\n",
    "\n",
    "# Get total quantity sold for each product\n",
    "product_sales = bill_items_df.groupby('product_id')['quantity'].sum().reset_index()\n",
    "product_sales.rename(columns={'quantity': 'total_quantity_sold'}, inplace=True)\n",
    "\n",
    "# Merge with products data to get stock dates\n",
    "sales_velocity_df = pd.merge(product_sales, products_df[['product_id', 'name', 'category_id', 'stock_date']], on='product_id')\n",
    "\n",
    "# Add category names\n",
    "sales_velocity_df = pd.merge(sales_velocity_df, categories_df, on='category_id')\n",
    "\n",
    "# Calculate a realistic sold_out_date based on sales volume and stock date\n",
    "# Higher sales means product sells out faster\n",
    "sales_velocity_df['initial_stock_quantity'] = np.random.randint(50, 200, len(sales_velocity_df))\n",
    "sales_velocity_df['remaining_stock'] = sales_velocity_df['initial_stock_quantity'] - sales_velocity_df['total_quantity_sold']\n",
    "\n",
    "# Estimate days to sell out based on quantity sold and initial stock\n",
    "sales_velocity_df['days_to_sell_out'] = np.where(\n",
    "    sales_velocity_df['remaining_stock'] <= 0,\n",
    "    # If sold out, calculate realistic days based on total quantity sold\n",
    "    np.ceil(sales_velocity_df['initial_stock_quantity'] / (sales_velocity_df['total_quantity_sold'] / 30 + 0.1)),\n",
    "    # If not sold out, use None to indicate not sold out yet\n",
    "    None\n",
    ")\n",
    "\n",
    "# Calculate sold out date for products that have sold out\n",
    "sales_velocity_df['sold_out_date'] = [\n",
    "    stock_date + timedelta(days=days) if days is not None else None\n",
    "    for stock_date, days in zip(sales_velocity_df['stock_date'], sales_velocity_df['days_to_sell_out'])\n",
    "]\n",
    "\n",
    "# Flag products that have sold out\n",
    "sales_velocity_df['is_sold_out'] = sales_velocity_df['sold_out_date'].notnull()\n",
    "\n",
    "print(\"Sales Velocity Dataset (first 10 rows):\")\n",
    "display(sales_velocity_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3a9b3",
   "metadata": {},
   "source": [
    "## 3. Product Sales Analysis\n",
    "\n",
    "Now that we have our sample data, let's analyze product sales to address Use Case 1:\n",
    "\n",
    "1. **Sales Velocity**: Which products sell the fastest?\n",
    "2. **Category Performance**: Which categories of products sell the fastest?\n",
    "3. **Top Sellers**: Which products sell in the highest quantities?\n",
    "\n",
    "These insights will help business owners make better inventory and stocking decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826156ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Analyze Sales Velocity - Which products sell the fastest?\n",
    "\n",
    "# Filter to only include products that have sold out\n",
    "sold_out_products = sales_velocity_df[sales_velocity_df['is_sold_out']].copy()\n",
    "\n",
    "# Calculate sales velocity (days to sell out)\n",
    "sold_out_products = sold_out_products.sort_values('days_to_sell_out')\n",
    "\n",
    "print(\"Products by Sales Velocity (Fastest Selling First):\")\n",
    "display(sold_out_products[['product_id', 'name', 'name_y', 'initial_stock_quantity', \n",
    "                          'total_quantity_sold', 'days_to_sell_out']].head(10).rename(\n",
    "                              columns={'name_y': 'category'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d22a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Analyze Category Performance - Which categories sell the fastest?\n",
    "\n",
    "# Calculate average days to sell out by category\n",
    "category_velocity = sold_out_products.groupby('name_y')['days_to_sell_out'].agg(['mean', 'count']).reset_index()\n",
    "category_velocity = category_velocity.sort_values('mean')\n",
    "category_velocity.rename(columns={'name_y': 'category', 'mean': 'avg_days_to_sell_out', 'count': 'products_sold_out'}, inplace=True)\n",
    "\n",
    "print(\"Categories by Sales Velocity (Fastest Selling First):\")\n",
    "display(category_velocity)\n",
    "\n",
    "# Calculate total sales by category\n",
    "category_sales = bill_items_df.merge(products_df[['product_id', 'category_id']], on='product_id')\n",
    "category_sales = category_sales.merge(categories_df, on='category_id')\n",
    "category_sales = category_sales.groupby('name')['quantity'].sum().reset_index()\n",
    "category_sales = category_sales.sort_values('quantity', ascending=False)\n",
    "category_sales.rename(columns={'name': 'category', 'quantity': 'total_quantity_sold'}, inplace=True)\n",
    "\n",
    "print(\"\\nCategories by Total Sales Volume:\")\n",
    "display(category_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71130e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Analyze Top Sellers - Which products sell in the highest quantities?\n",
    "\n",
    "# Aggregate sales by product\n",
    "product_quantity_sold = bill_items_df.groupby('product_id')['quantity'].sum().reset_index()\n",
    "top_products = product_quantity_sold.merge(products_df[['product_id', 'name', 'category_id']], on='product_id')\n",
    "top_products = top_products.merge(categories_df, on='category_id')\n",
    "top_products = top_products.sort_values('quantity', ascending=False)\n",
    "\n",
    "print(\"Top 15 Products by Sales Volume:\")\n",
    "display(top_products[['product_id', 'name_x', 'name_y', 'quantity']].head(15).rename(\n",
    "    columns={'name_x': 'product', 'name_y': 'category', 'quantity': 'total_quantity_sold'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c3363",
   "metadata": {},
   "source": [
    "## 4. Customer Purchase Behavior Analysis\n",
    "\n",
    "For Use Case 2, we need to analyze customer purchase behavior:\n",
    "\n",
    "1. **Repeat Customers**: Which customers repeatedly buy the same products?\n",
    "2. **Purchase Patterns**: Are there any patterns in purchase behavior by nationality or age?\n",
    "3. **Customer Segmentation**: Identify different customer segments based on purchase behavior.\n",
    "\n",
    "These insights will help with targeted marketing and personalized promotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29cceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Analyze Repeat Customers - Which customers repeatedly buy the same products?\n",
    "\n",
    "# Join bill items with bills to get customer information\n",
    "customer_purchases = bill_items_df.merge(bills_df[['bill_id', 'card_id', 'timestamp']], on='bill_id')\n",
    "\n",
    "# Count how many times each customer bought each product\n",
    "customer_product_frequency = customer_purchases.groupby(['card_id', 'product_id'])['bill_id'].count().reset_index()\n",
    "customer_product_frequency.rename(columns={'bill_id': 'purchase_count'}, inplace=True)\n",
    "\n",
    "# Filter to only include repeat purchases (bought same product 2+ times)\n",
    "repeat_purchases = customer_product_frequency[customer_product_frequency['purchase_count'] > 1]\n",
    "repeat_purchases = repeat_purchases.sort_values('purchase_count', ascending=False)\n",
    "\n",
    "# Add product and customer names\n",
    "repeat_purchases = repeat_purchases.merge(products_df[['product_id', 'name']], on='product_id')\n",
    "repeat_purchases = repeat_purchases.merge(customers_df[['card_id', 'first_name', 'last_name', 'nationality']], on='card_id')\n",
    "\n",
    "print(\"Top Repeat Customers by Product:\")\n",
    "display(repeat_purchases.head(15).rename(columns={'name': 'product'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a52be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Analyze Purchase Patterns by Nationality\n",
    "\n",
    "# Join all the necessary tables\n",
    "nationality_purchases = bill_items_df.merge(bills_df[['bill_id', 'card_id']], on='bill_id')\n",
    "nationality_purchases = nationality_purchases.merge(customers_df[['card_id', 'nationality']], on='card_id')\n",
    "nationality_purchases = nationality_purchases.merge(products_df[['product_id', 'category_id']], on='product_id')\n",
    "nationality_purchases = nationality_purchases.merge(categories_df, on='category_id')\n",
    "\n",
    "# Analyze category preferences by nationality\n",
    "nationality_category_pref = nationality_purchases.groupby(['nationality', 'name'])['quantity'].sum().reset_index()\n",
    "nationality_category_pref = nationality_category_pref.sort_values(['nationality', 'quantity'], ascending=[True, False])\n",
    "nationality_category_pref.rename(columns={'name': 'category', 'quantity': 'total_quantity'}, inplace=True)\n",
    "\n",
    "# Get top category for each nationality\n",
    "top_categories_by_nationality = nationality_category_pref.loc[nationality_category_pref.groupby('nationality')['total_quantity'].idxmax()]\n",
    "\n",
    "print(\"Top Product Category by Nationality:\")\n",
    "display(top_categories_by_nationality)\n",
    "\n",
    "# Calculate relative preference (percentage of each category within nationality)\n",
    "nationality_totals = nationality_category_pref.groupby('nationality')['total_quantity'].sum().reset_index()\n",
    "nationality_category_pref = nationality_category_pref.merge(nationality_totals, on='nationality', suffixes=('', '_total'))\n",
    "nationality_category_pref['percentage'] = (nationality_category_pref['total_quantity'] / nationality_category_pref['total_quantity_total'] * 100).round(2)\n",
    "\n",
    "print(\"\\nTop 3 Categories for Each Nationality:\")\n",
    "for nationality in nationality_category_pref['nationality'].unique():\n",
    "    print(f\"\\n{nationality}:\")\n",
    "    display(nationality_category_pref[nationality_category_pref['nationality'] == nationality].sort_values('total_quantity', ascending=False).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61947e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Customer Segmentation - Identify different customer segments\n",
    "\n",
    "# Calculate total spending by customer\n",
    "customer_spending = bill_items_df.merge(bills_df[['bill_id', 'card_id']], on='bill_id')\n",
    "customer_spending = customer_spending.groupby('card_id')['total_price'].sum().reset_index()\n",
    "customer_spending.rename(columns={'total_price': 'total_spending'}, inplace=True)\n",
    "\n",
    "# Calculate purchase frequency (number of unique bills)\n",
    "purchase_frequency = bills_df.groupby('card_id')['bill_id'].nunique().reset_index()\n",
    "purchase_frequency.rename(columns={'bill_id': 'visit_count'}, inplace=True)\n",
    "\n",
    "# Calculate average basket size\n",
    "basket_size = bills_df.merge(bill_items_df, on='bill_id')\n",
    "basket_size = basket_size.groupby(['card_id', 'bill_id'])['quantity'].sum().reset_index()\n",
    "basket_size = basket_size.groupby('card_id')['quantity'].mean().reset_index()\n",
    "basket_size.rename(columns={'quantity': 'avg_basket_size'}, inplace=True)\n",
    "\n",
    "# Combine metrics for segmentation\n",
    "customer_segments = customer_spending.merge(purchase_frequency, on='card_id')\n",
    "customer_segments = customer_segments.merge(basket_size, on='card_id')\n",
    "customer_segments = customer_segments.merge(customers_df[['card_id', 'first_name', 'last_name', 'nationality', 'age']], on='card_id')\n",
    "\n",
    "# Calculate recency (days since last purchase)\n",
    "last_purchase_date = bills_df.groupby('card_id')['timestamp'].max().reset_index()\n",
    "last_purchase_date['days_since_last_purchase'] = (datetime.now() - last_purchase_date['timestamp']).dt.days\n",
    "customer_segments = customer_segments.merge(last_purchase_date[['card_id', 'days_since_last_purchase']], on='card_id')\n",
    "\n",
    "# Create simple segments based on spending and frequency\n",
    "def create_segment(row):\n",
    "    if row['total_spending'] > 500 and row['visit_count'] > 5:\n",
    "        return 'High-Value Regular'\n",
    "    elif row['total_spending'] > 500:\n",
    "        return 'Big Spender'\n",
    "    elif row['visit_count'] > 5:\n",
    "        return 'Frequent Visitor'\n",
    "    elif row['days_since_last_purchase'] < 7:\n",
    "        return 'Recent Customer'\n",
    "    else:\n",
    "        return 'Occasional Shopper'\n",
    "\n",
    "customer_segments['segment'] = customer_segments.apply(create_segment, axis=1)\n",
    "\n",
    "# Show segment distribution\n",
    "segment_counts = customer_segments.groupby('segment')['card_id'].count().reset_index()\n",
    "segment_counts.rename(columns={'card_id': 'customer_count'}, inplace=True)\n",
    "segment_counts['percentage'] = (segment_counts['customer_count'] / segment_counts['customer_count'].sum() * 100).round(2)\n",
    "\n",
    "print(\"Customer Segments Distribution:\")\n",
    "display(segment_counts)\n",
    "\n",
    "# Show examples of customers in each segment\n",
    "print(\"\\nCustomer Segment Examples:\")\n",
    "for segment in customer_segments['segment'].unique():\n",
    "    print(f\"\\n{segment} Examples:\")\n",
    "    display(customer_segments[customer_segments['segment'] == segment].sort_values('total_spending', ascending=False).head(3)[\n",
    "        ['card_id', 'first_name', 'last_name', 'total_spending', 'visit_count', 'avg_basket_size', 'days_since_last_purchase']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c2a496",
   "metadata": {},
   "source": [
    "## 5. Data Privacy: Anonymization\n",
    "\n",
    "Since EDEKA is based in Germany, GDPR compliance is essential. Let's demonstrate how to anonymize customer data while still maintaining the ability to perform analytics:\n",
    "\n",
    "1. **Hash Customer IDs**: Replace card_id with a hashed version that can't be reversed\n",
    "2. **Remove Personal Information**: Remove first and last names from analytics data\n",
    "3. **Aggregate Sensitive Data**: Present nationality data only in aggregated form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Create anonymized version of customer data\n",
    "\n",
    "def hash_id(id_value, salt=\"EDEKA_ANALYTICS\"):\n",
    "    \"\"\"Create a hashed version of an ID that can't be reversed\"\"\"\n",
    "    to_hash = f\"{salt}_{id_value}\"\n",
    "    return hashlib.sha256(to_hash.encode()).hexdigest()[:16]  # Take first 16 chars for readability\n",
    "\n",
    "# Create anonymized customer data\n",
    "anonymized_customers = customers_df.copy()\n",
    "anonymized_customers['hashed_card_id'] = anonymized_customers['card_id'].apply(hash_id)\n",
    "anonymized_customers.drop(['first_name', 'last_name', 'card_id'], axis=1, inplace=True)\n",
    "\n",
    "print(\"Anonymized Customer Data (GDPR Compliant):\")\n",
    "display(anonymized_customers.head(10))\n",
    "\n",
    "# Create anonymized bills data\n",
    "anonymized_bills = bills_df.copy()\n",
    "anonymized_bills['hashed_card_id'] = anonymized_bills['card_id'].apply(hash_id)\n",
    "anonymized_bills.drop(['card_id'], axis=1, inplace=True)\n",
    "\n",
    "print(\"\\nAnonymized Bills Data:\")\n",
    "display(anonymized_bills.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5cc5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Demonstrate aggregated nationality data for analytics\n",
    "\n",
    "# This shows how to present nationality data in an aggregated form\n",
    "# rather than linking it directly to individual customers\n",
    "\n",
    "# Aggregated sales by nationality and product category\n",
    "nationality_category_agg = nationality_purchases.groupby(['nationality', 'name'])['quantity'].sum().reset_index()\n",
    "nationality_category_agg.rename(columns={'name': 'category', 'quantity': 'total_quantity'}, inplace=True)\n",
    "nationality_category_agg = nationality_category_agg.sort_values(['nationality', 'total_quantity'], ascending=[True, False])\n",
    "\n",
    "# Only show categories with significant sales (privacy protection)\n",
    "min_threshold = 10  # Only show categories with at least 10 items sold\n",
    "nationality_category_agg = nationality_category_agg[nationality_category_agg['total_quantity'] >= min_threshold]\n",
    "\n",
    "print(\"Aggregated Sales by Nationality and Category (GDPR Compliant):\")\n",
    "display(nationality_category_agg.head(15))\n",
    "\n",
    "# Age groups instead of specific ages\n",
    "anonymized_customers['age_group'] = pd.cut(\n",
    "    anonymized_customers['age'], \n",
    "    bins=[0, 25, 35, 50, 65, 100],\n",
    "    labels=['18-25', '26-35', '36-50', '51-65', '65+']\n",
    ")\n",
    "\n",
    "age_group_counts = anonymized_customers.groupby(['nationality', 'age_group']).size().reset_index()\n",
    "age_group_counts.rename(columns={0: 'customer_count'}, inplace=True)\n",
    "\n",
    "# Only show groups with at least 3 customers (k-anonymity with k=3)\n",
    "age_group_counts = age_group_counts[age_group_counts['customer_count'] >= 3]\n",
    "\n",
    "print(\"\\nAggregated Customer Demographics (GDPR Compliant):\")\n",
    "display(age_group_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b882a0d8",
   "metadata": {},
   "source": [
    "## 6. Visualizing Insights with Charts\n",
    "\n",
    "For Use Case 3, we need to create visualizations that would be included in a dashboard. Let's create a variety of charts to visualize the insights we've found:\n",
    "\n",
    "1. **Bar Chart**: Top-selling products\n",
    "2. **Pie Chart**: Sales by product category\n",
    "3. **Line Chart**: Customer purchase trends over time\n",
    "4. **Grouped Bar Chart**: Sales by nationality\n",
    "5. **Heatmap**: Product quality vs demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Bar Chart: Top-selling products\n",
    "\n",
    "# Get top 10 products by sales volume\n",
    "top10_products = top_products.head(10).rename(columns={'name_x': 'product', 'name_y': 'category'})\n",
    "\n",
    "# Create a horizontal bar chart with Plotly\n",
    "fig = px.bar(\n",
    "    top10_products,\n",
    "    y='product',\n",
    "    x='quantity',\n",
    "    color='category',\n",
    "    orientation='h',\n",
    "    title='Top 10 Products by Sales Volume',\n",
    "    labels={'quantity': 'Units Sold', 'product': 'Product', 'category': 'Category'},\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis={'categoryorder': 'total ascending'},\n",
    "    xaxis_title='Units Sold',\n",
    "    yaxis_title='Product',\n",
    "    legend_title='Category'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21526814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Pie Chart: Sales by product category\n",
    "\n",
    "# Create a pie chart of sales by category\n",
    "fig = px.pie(\n",
    "    category_sales,\n",
    "    values='total_quantity_sold',\n",
    "    names='category',\n",
    "    title='Sales Distribution by Product Category',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    "    hole=0.3\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.update_layout(\n",
    "    legend_title='Category',\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=-0.1, xanchor='center', x=0.5)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f86643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Line Chart: Customer purchase trends over time\n",
    "\n",
    "# Aggregate sales by date\n",
    "daily_sales = bills_df.merge(bill_items_df, on='bill_id')\n",
    "daily_sales['date'] = daily_sales['timestamp'].dt.date\n",
    "daily_sales = daily_sales.groupby('date')['quantity'].sum().reset_index()\n",
    "daily_sales = daily_sales.sort_values('date')\n",
    "\n",
    "# Create a line chart of daily sales volume\n",
    "fig = px.line(\n",
    "    daily_sales,\n",
    "    x='date',\n",
    "    y='quantity',\n",
    "    title='Daily Sales Volume Trend',\n",
    "    labels={'quantity': 'Units Sold', 'date': 'Date'},\n",
    "    markers=True\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Units Sold'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Aggregate sales by category and date\n",
    "category_daily_sales = bills_df.merge(bill_items_df, on='bill_id')\n",
    "category_daily_sales = category_daily_sales.merge(products_df[['product_id', 'category_id']], on='product_id')\n",
    "category_daily_sales = category_daily_sales.merge(categories_df, on='category_id')\n",
    "category_daily_sales['date'] = category_daily_sales['timestamp'].dt.date\n",
    "category_daily_sales = category_daily_sales.groupby(['date', 'name'])['quantity'].sum().reset_index()\n",
    "category_daily_sales = category_daily_sales.rename(columns={'name': 'category'})\n",
    "\n",
    "# Filter to top 5 categories for clarity\n",
    "top_categories = category_sales.head(5)['category'].tolist()\n",
    "category_daily_sales = category_daily_sales[category_daily_sales['category'].isin(top_categories)]\n",
    "\n",
    "# Create a multi-line chart for top 5 categories\n",
    "fig = px.line(\n",
    "    category_daily_sales,\n",
    "    x='date',\n",
    "    y='quantity',\n",
    "    color='category',\n",
    "    title='Daily Sales Trend by Top 5 Categories',\n",
    "    labels={'quantity': 'Units Sold', 'date': 'Date', 'category': 'Category'}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Units Sold',\n",
    "    legend_title='Category'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
